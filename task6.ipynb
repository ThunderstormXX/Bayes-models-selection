{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m norm\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstatsmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmultitest\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msmt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import statsmodels.stats.multitest as smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gen(n ) :\n",
    "    arr = []\n",
    "    for j in range(n) :\n",
    "        arr.append([np.random.normal(0,1.0) , np.random.normal(0,1.0)])\n",
    "    return np.array(arr).T\n",
    "def get_corr_sample(sample , rho) :\n",
    "    alpha = (np.sqrt(1+rho) + np.sqrt(1-rho))/2\n",
    "    beta = (np.sqrt(1+rho) - np.sqrt(1-rho))/2\n",
    "    A_rho = [[alpha , beta],[beta , alpha]]\n",
    "    return A_rho@sample\n",
    "def T(X) :\n",
    "    return np.sum(X[0]*X[1])/len(X[0])\n",
    "def T_2(X) :\n",
    "    return np.sum((X[0]-X[1])**2)/len(X[0])/2\n",
    "def get_W(n , criterion , num_samples ,rho_arr) :\n",
    "    W = []\n",
    "    for rho in rho_arr :\n",
    "        count_reject = []\n",
    "        for _ in range(num_samples) :\n",
    "            sample = sample_gen(n)\n",
    "            sample = get_corr_sample(sample , rho)\n",
    "            count_reject.append(criterion(sample))\n",
    "        W.append( sum(count_reject) / num_samples)\n",
    "    return W\n",
    "def crit_1(sample)  :\n",
    "    return np.abs(T(sample)) > 20/n\n",
    "def crit_2(sample) :\n",
    "    return np.abs(T_2(sample)-1) > 1.96*np.sqrt(2)/np.sqrt(n)\n",
    "def crit_1_by_alpha(sample , alpha ) :\n",
    "    return np.abs(T(sample)) > 1/(len(sample) * alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_values(num_samples ,rho , n=100 ) :\n",
    "    p_values = []\n",
    "    sigma = np.sqrt(1/n)\n",
    "    for _ in range(num_samples) :\n",
    "        sample = sample_gen(n)\n",
    "        sample = get_corr_sample(sample , rho)\n",
    "        stat = np.abs(T(sample))\n",
    "        left = norm.cdf( -stat , loc=0, scale=sigma )\n",
    "        p_values.append(2*left)\n",
    "    return np.array(p_values)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FWER = P(V>0) . V - это число сэмплов , когда мы отвергли гипотезу {$\\rho = 0$} при ее верности. Хотим оценить эту вероятность , значит нужен еще один цикл сэмплирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "rho_1  = 0\n",
    "rho_2 = 0.2\n",
    "num_samples = 500\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посэмплируем и проверим как работают поправки"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Без поправки Бонферони - FWER :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "N_sampling = 100\n",
    "counter = 0\n",
    "for j in range(N_sampling) :\n",
    "    p_values_1 = get_p_values(num_samples,rho_1,n)\n",
    "    p_values_2 = get_p_values(num_samples,rho_2,n)\n",
    "    counter += np.sum(p_values_1 < 0.05) > 0 \n",
    "\n",
    "print(counter /N_sampling)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FWER С поправкой  Бонферони: (как видим соотвестсвует теореме о том что поправка позволяет контролировать FWER на уровне $\\alpha$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n"
     ]
    }
   ],
   "source": [
    "N_sampling = 100\n",
    "counter = 0\n",
    "for j in range(N_sampling) :\n",
    "    p_values_1 = get_p_values(num_samples,rho_1,n)\n",
    "    new_p_values_1 = p_values_1*1000\n",
    "    \n",
    "    counter += np.sum(new_p_values_1 < 0.05) > 0\n",
    "\n",
    "print(counter /N_sampling) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FDR = $ E( \\frac{\\textbf{Число отвергнутых верных}}{отвергнутых} )$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FDR без поправки :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09050189686203985\n"
     ]
    }
   ],
   "source": [
    "N_sampling = 100\n",
    "value = 0\n",
    "for j in range(N_sampling) :\n",
    "    p_values_1 = get_p_values(num_samples,rho_1,n)\n",
    "    p_values_2 = get_p_values(num_samples,rho_2,n)\n",
    "    \n",
    "    cnt_1 = np.sum( p_values_1 < 0.05 )\n",
    "    cnt_2 = cnt_1 + np.sum( p_values_2 < 0.05)\n",
    "    if cnt_2 != 0 :\n",
    "        value += cnt_1/cnt_2\n",
    "\n",
    "print( value/N_sampling) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теперь реализуем поправку Бенджамина-Хохберга :\n",
    "Как видим она контролируется примерно : FDR < $\\frac{m_0}{m}\\alpha$  (Примерно , так как у нас очень маленький сэмплинг , а большой очень долго запускать), А именно FDR $<\\frac{\\alpha}{2}$\n",
    "По крайней мере она контролируется на уровне $\\alpha$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FDR с поправкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0293624896143638\n"
     ]
    }
   ],
   "source": [
    "N_sampling = 100\n",
    "value = 0\n",
    "for j in range(N_sampling) :\n",
    "    p_values_1 = get_p_values(num_samples,rho_1,n)\n",
    "    p_values_2 = get_p_values(num_samples,rho_2,n)\n",
    "    p_values__all = np.concatenate([p_values_1,p_values_2])\n",
    "    sorted_index = np.argsort(p_values__all)\n",
    "    p_values__all = p_values__all[sorted_index]\n",
    "    corrected_p_values = smt.multipletests( p_values__all, method='fdr_bh')[1]\n",
    "\n",
    "    inverse_index = np.argsort(sorted_index)\n",
    "\n",
    "    new_p_values_all = corrected_p_values[inverse_index]\n",
    "\n",
    "    new_p_values_1 = new_p_values_all[:500]\n",
    "    new_p_values_2 = new_p_values_all[500:]\n",
    "    cnt_1 = np.sum( new_p_values_1 < 0.05 )\n",
    "    cnt_2 = cnt_1 + np.sum( new_p_values_2 < 0.05)\n",
    "    if cnt_2 != 0 :\n",
    "        value += cnt_1/cnt_2\n",
    "print( value/N_sampling) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь Генерим 1000 с.в. с одинаковым $\\rho = 0$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FWER без поправки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "N_sampling = 100\n",
    "counter = 0\n",
    "for j in range(N_sampling) :\n",
    "    p_values_1 = get_p_values(1000,rho_1,n)\n",
    "    counter += np.sum(p_values_1 < 0.05) > 0 \n",
    "\n",
    "print(counter /N_sampling)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FWER С поправкой Бонферрони : (FWER <=$\\alpha$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "N_sampling = 100\n",
    "counter = 0\n",
    "for j in range(N_sampling) :\n",
    "    p_values_1 = get_p_values(2*num_samples,rho_1,n)\n",
    "    new_p_values_1 = p_values_1*1000\n",
    "    \n",
    "    counter += np.sum(new_p_values_1 < 0.05) > 0\n",
    "\n",
    "print(counter /N_sampling) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FDR  без поправки : (В случае когда неверных гипотез = 0 ,то  FDR = FWER )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "N_sampling = 100\n",
    "value = 0\n",
    "for j in range(N_sampling) :\n",
    "    p_values_1 = get_p_values(2*num_samples,rho_1,n)\n",
    "    \n",
    "    cnt = np.sum( p_values_1 < 0.05)\n",
    "    if cnt != 0 :   \n",
    "        value +=1\n",
    "    \n",
    "print( value/N_sampling) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  FDR С поправкой Бенджаммини-Хохберга ( = FWER , т.к. E(1_{R>0}) = P(R>0) =P(V>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06\n"
     ]
    }
   ],
   "source": [
    "N_sampling = 100\n",
    "value = 0\n",
    "for j in range(N_sampling) :\n",
    "    p_values_1 = get_p_values(2*num_samples,rho_1,n)\n",
    "    sorted_index = np.argsort(p_values_1)\n",
    "    p_values_1 = p_values_1[sorted_index]\n",
    "    corrected_p_values = smt.multipletests( p_values_1, method='fdr_bh')[1]\n",
    "\n",
    "    inverse_index = np.argsort(sorted_index)\n",
    "\n",
    "    new_p_values_1 = corrected_p_values[inverse_index]\n",
    "\n",
    "    value += np.sum( new_p_values_1 < 0.05 ) > 0\n",
    "print( value/N_sampling) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
